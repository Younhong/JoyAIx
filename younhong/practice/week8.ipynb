{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGD(object):\n",
    "    \"\"\"Adaptive Linear Neuron Classifier\"\"\"\n",
    "    def __init__(self, eta = 0.01, epochs = 10, random_seed = 1):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_seed)\n",
    "        # w size is increased by one for bias\n",
    "        self.w = np.random.random(size = X.shape[1] + 1)\n",
    "        \n",
    "        self.maxy = y.max()\n",
    "        self.miny = y.min()\n",
    "        \n",
    "        self.cost_ = []\n",
    "        self.w_ = np.array([self.w])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            Z = self.net_input(X)\n",
    "            yhat = self.activation(Z)\n",
    "            errors = (y - yhat)\n",
    "            self.w[1:] += self.eta * np.dot(errors, X)\n",
    "            self.w[0] += self.eta * np.sum(errors)\n",
    "            cost = 0.5 * np.sum(errors**2)\n",
    "            self.cost_.append(cost)\n",
    "            self.w_ = np.vstack([self.w_, self.w])\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        z = np.dot(X, self.w[1:]) + self.w[0]\n",
    "        return z\n",
    "    \n",
    "    def activation(self, X):\n",
    "        return X\n",
    "    \n",
    "    def predict(self, X):\n",
    "        mid = (self.maxy + self.miny) / 2\n",
    "        Z = self.net_input(X)\n",
    "        yhat = self.activation(Z)\n",
    "        return np.where(yhat > mid, self.maxy, self.miny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/'\n",
    "                'ml/machine-learning-databases/'\n",
    "                'iris/iris.data', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joy\n",
    "X, y = joy.iris_data()\n",
    "ada = AdalineGD(epochs=10, eta=0.1)\n",
    "ada.fit(X,y)\n",
    "joy.plot_xyw(X,y, ada.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(ada.cost_)+1), np.log10(ada.cost_), marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log(Sum-squared-error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = joy.iris_data()\n",
    "ada = AdalineGD(epochs=10, eta=0.1)\n",
    "ada.fit(X,y)\n",
    "plt.plot(range(1, len(ada.cost_)+1), np.log10(ada.cost_), marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log(Sum-squared-error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = joy.iris_data()\n",
    "ada = AdalineGD(epochs=10, eta=0.0001)\n",
    "ada.fit(X,y)\n",
    "plt.plot(range(1, len(ada.cost_)+1), np.log10(ada.cost_), marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('log(Sum-squared-error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joy\n",
    "Xstd, y = joy.iris_data(standardized=True)\n",
    "ada = AdalineGD(epochs=10, eta=0.001)\n",
    "ada.fit(Xstd,y)\n",
    "joy.plot_xyw(Xstd, y, ada.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile code/AdalineGD_Momentum.py\n",
    "# Implementation of  Widrow's Adaptive Linear classifier algorithm\n",
    "# Author: idebtor@gmail.com\n",
    "# 2018.03.21 - Creation\n",
    "\n",
    "class AdalineGD_Momentum(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "    Parameters\n",
    "        eta: float, Learning rate (between 0.0 and 1.0)\n",
    "        epochs: int, Passes over the training dataset.\n",
    "        random_seed : int, random funtion seed for reproducibility\n",
    "\n",
    "    Attributes\n",
    "        w_ : 1d-array, Weights after fitting.\n",
    "        cost_ : list, Sum-of-squares cost function value in each epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, epochs=10, random_seed=1):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "        Parameters\n",
    "            X: numpy.ndarray, shape=(n_samples, m_features), \n",
    "            y: class label, array-like, shape = (n_samples, )\n",
    "        Returns\n",
    "            self : object\n",
    "        \"\"\"            \n",
    "        np.random.seed(self.random_seed)\n",
    "        self.w = np.random.random(size=X.shape[1] + 1)\n",
    "            \n",
    "        self.maxy, self.miny = y.max(), y.min()\n",
    "        self.cost_ = []\n",
    "        self.w_ = np.array([self.w])\n",
    "        \n",
    "        \"\"\"Momentum\"\"\"\n",
    "        self.v1 = np.zeros_like(self.w[1:])\n",
    "        self.v2 = np.zeros_like(self.w[0])\n",
    "        gamma = 0.5\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            yhat = self.activation(self.net_input(X))\n",
    "            errors = (y - yhat)\n",
    "            \n",
    "            self.v1 = gamma * self.v1 + self.eta * np.dot(errors, X)\n",
    "            self.v2 = gamma * self.v2 + self.eta * np.sum(errors)\n",
    "            \n",
    "            self.w[1:] += self.v1 #self.eta * np.dot(errors, X)\n",
    "            self.w[0] += self.v2 #self.eta * np.sum(errors)\n",
    "            cost = 0.5 * np.sum(errors**2)\n",
    "            self.cost_.append(cost)\n",
    "            self.w_ = np.vstack([self.w_, self.w]) \n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):            \n",
    "        \"\"\"Compute the value of z, net input  \"\"\"\n",
    "        return np.dot(X, self.w[1:]) + self.w[0]\n",
    "\n",
    "    def activation(self, X):  \n",
    "        \"\"\"Identity activation function: \"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):      \n",
    "        \"\"\"Predict the class label with  \"\"\"\n",
    "        mid = (self.maxy + self.miny) / 2\n",
    "        Z = self.net_input(X)\n",
    "        yhat = self.activation(Z)\n",
    "        return np.where(yhat > mid, self.maxy, self.miny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "g = lambda x : 1 / (1 + np.exp(-x))\n",
    "x = np.array([1, 0])\n",
    "\n",
    "# feed forward propagation\n",
    "W1 = np.array([[0.1, 0.4], [0.2, 0.2], [0.3, 0.0]])\n",
    "z1 = np.dot(W1, x)\n",
    "a1 = g(z1)\n",
    "W2 = np.array([[0.5, 0.3, 0.4], [0.3, 0.2, 0.1]])\n",
    "z2 = np.dot(W2, a1)\n",
    "yhat = g(z2)\n",
    "print('yhat=', yhat)\n",
    "\n",
    "# error backpropagation\n",
    "y = np.array([1, 1])\n",
    "E2 = y - yhat\n",
    "E1 = np.dot(W2.T, E2)\n",
    "#print('E1=', E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "g = lambda x : relu(x)\n",
    "x = np.array([1, 0])\n",
    "\n",
    "# feed forward propagation\n",
    "W1 = np.array([[0.1, 0.4], [0.2, 0.2], [0.3, 0.0]])\n",
    "z1 = np.dot(W1, x)\n",
    "a1 = g(z1)\n",
    "W2 = np.array([[0.5, 0.3, 0.4], [0.3, 0.2, 0.1]])\n",
    "z2 = np.dot(W2, a1)\n",
    "yhat = g(z2)\n",
    "print('yhat=', yhat)\n",
    "\n",
    "# error backpropagation\n",
    "y = np.array([1, 1])\n",
    "E2 = y - yhat\n",
    "print('E2=', E2)\n",
    "E1 = np.dot(W2.T, E2)\n",
    "print('E1=', E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.105  0.294  0.195]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import activate_function as af\n",
    "x = np.array([1,0])\n",
    "w1 = np.array([[0.1, 0.4], [0.2,0.2], [-0.3, 0]])\n",
    "z1 = np.dot(w1, x)\n",
    "a1 = af.relu(z1)\n",
    "# print(a1)\n",
    "\n",
    "w2 = np.array([[-0.3, 0.2, 0.1], [0.2, 0.1, 0.1]])\n",
    "z2 = np.dot(w2, a1)\n",
    "a2 = af.relu(z2)\n",
    "# print(a2)\n",
    "\n",
    "y = np.array([1,1])\n",
    "e2 = y - a2\n",
    "e1 = np.dot(w2.T, e2)\n",
    "print(e1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
